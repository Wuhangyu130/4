模型融合简单来说就是通过对一组的基分类器以某种方式进行组合，以提升模型整体性能的方法。当然，模型融合不能起到决定性作用，在影响模型结果的因素中，一般来说是数据>特征>模型>模型融合。在业界流传着这么一句话，数据和特征决定了机器学习的上限，而模型和算法只是在逼近这个上限而已。

简单加权融合:
回归（分类概率）：算术平均融合（Arithmetic mean），几何平 均融合（Geometric mean）；
分类：投票（Voting)
综合：排序融合(Rank averaging)，log融合

stacking/blending:
构建多层模型，并利用预测结果再拟合预测。

boosting/bagging（在xgboost，Adaboost,GBDT中已经用到）:
多树的提升方法
